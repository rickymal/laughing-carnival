{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "284e10eb-7427-44d6-8ece-388d54e81edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Henrique Mauler Borges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7551b18c-0bdc-4dd0-9ffd-5fd791933832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from wordcloud import STOPWORDS\n",
    "from collections import defaultdict\n",
    "import text_hammer as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40f36ece-0bcf-4a82-9953-95c1e869e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv').loc[:,['id','text','target']]\n",
    "test_data = pd.read_csv('test.csv').loc[:,['id','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4afd0684-73fb-4f2b-8681-f7f7f3141f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   0                 Just happened a terrible car crash\n",
       "1   2  Heard about #earthquake is different cities, s...\n",
       "2   3  there is a forest fire at spot pond, geese are...\n",
       "3   9           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f29bea9-72bd-41e3-89f5-2cf26ef4d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3244e044-d788-4bc0-a555-0e68a89c7d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_data.loc[:,'text'],train_data.loc[:,'target'],\n",
    "                                                    test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "837a67d7-bb09-4461-a204-cf4f39f1fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "764cc0d2-c547-4097-b5a7-54ddee67668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec95415-131f-4bee-8a6e-ac7e49b4b045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79ed4bce-a93c-4d32-833c-e9dbdda76562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english' , ngram_range=(1,1),tokenizer=LemmaTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33e6defb-11c6-4ab1-a43d-3dc863d62647",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(x_train)\n",
    "#vectorizer.get_feature_names_out()\n",
    "x_train=vectorizer.transform(x_train)\n",
    "x_test=vectorizer.transform(x_test)\n",
    "test_vectors = vectorizer.transform(test_data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41c41caf-afb9-43be-a9c3-2db583e93105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f810dd65-83a1-4eef-ad48-d757b99f0bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2a1b087-2c91-4eae-84a5-7d88d1c75a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7863397548161121"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score , confusion_matrix\n",
    "accuracy_score(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25018587-26e1-4a64-a5c3-0d49c68a65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza dos dados\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf02f594-1d27-4be1-8435-c7f9eb611ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing_from_hammer(df,col_name):\n",
    "    df = copy(df)\n",
    "    column = col_name\n",
    "    df[column] = df[column].apply(lambda x:str(x).lower())\n",
    "#     df[column] = df[column].progress_apply(lambda x: th.cont_exp(x)) #you're -> you are; i'm -> i am\n",
    "    df[column] = df[column].apply(lambda x: th.remove_emails(x))\n",
    "    df[column] = df[column].apply(lambda x: th.remove_html_tags(x))\n",
    "#     df[column] = df[column].progress_apply(lambda x: ps.remove_stopwords(x))\n",
    "    df[column] = df[column].apply(lambda x: th.remove_special_chars(x))\n",
    "    df[column] = df[column].apply(lambda x: th.remove_accented_chars(x))\n",
    "#     df[column] = df[column].progress_apply(lambda x: th.make_base(x)) #ran -> run,\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ffaaee0-1543-46e8-996f-b2c8f87c5871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1   4             Forest fire near La Ronge Sask. Canada       1\n",
       "2   5  All residents asked to 'shelter in place' are ...       1\n",
       "3   6  13,000 people receive #wildfires evacuation or...       1\n",
       "4   7  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7492944a-0564-46a9-8939-3936bdd33160",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_training_hammed = text_preprocessing_from_hammer(train_data,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01581bcb-5a7a-4bc2-a2b0-5f9e6c1597cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  our deeds are the reason of this earthquake ma...       1\n",
       "1   4              forest fire near la ronge sask canada       1\n",
       "2   5  all residents asked to shelter in place are be...       1\n",
       "3   6  13000 people receive wildfires evacuation orde...       1\n",
       "4   7  just got sent this photo from ruby alaska as s...       1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_training_hammed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f79c52b8-9d00-464b-bf9a-6b902a382224",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_for_training_hammed.loc[:,'text'],data_for_training_hammed.loc[:,'target'],\n",
    "                                                    test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c24653df-67ff-489d-a8ee-e2501220cc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\henri_m9qs9bn\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\henri_m9qs9bn\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer.fit(x_train)\n",
    "#vectorizer.get_feature_names_out()\n",
    "x_train=vectorizer.transform(x_train)\n",
    "x_test=vectorizer.transform(x_test)\n",
    "test_vectors = vectorizer.transform(test_data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef2b1437-f863-4879-aba0-c31ef4cdf266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd4cc876-c0af-4b9e-bc16-e5093bd2a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f275d718-1682-4d87-8ac1-567a73a5f076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8077933450087565"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score , confusion_matrix\n",
    "accuracy_score(y_test,predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
