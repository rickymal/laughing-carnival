{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "489e04d5-50ad-4936-923b-dfd1a44bea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52f59246-eb88-4dc8-bfed-df87c2de7f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc6d94f7-0150-40ea-a866-24c4c9288aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey', 'ya', 'believer']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"Hey ya believer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bcec59-53e6-4873-bed6-315b80c6a379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c59193f-ab64-452a-9648-c0a9fc87255b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572c0ec5-c4ee-4b1a-9116-3663fd2e9ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bc44df-f947-4091-9a0b-0340f89e0274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f0896b7-5990-4df9-ae1d-d632cb62f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = LemmaTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "125bee3d-1b85-4bed-8fca-c5bc580a922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_tk = \"This is an thing that i don't have any somebody\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcaa044e-6832-4cc5-9d60-7056fe77ca05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'an',\n",
       " 'thing',\n",
       " 'that',\n",
       " 'i',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'somebody']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk(str_tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe6f7bcd-1603-4653-9b82-ca93c286497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e21cace-2117-4311-9917-4b55573d26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = [\"One Geek helps Two Geeks\",\n",
    "            \"Two Geeks help Four Geeks\",\n",
    "            \"Each Geek helps many other Geeks at GeeksforGeeks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79a3bb17-061d-436a-bc98-0220206b4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b0ef7fe-11de-473f-bb96-964839eeec54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d220cd6-b3e4-4569-b58a-a143515cc1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  {'one': 9, 'geek': 3, 'helps': 7, 'two': 11, 'geeks': 4, 'help': 6, 'four': 2, 'each': 1, 'many': 8, 'other': 10, 'at': 0, 'geeksforgeeks': 5}\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary: \", vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37028618-062f-4f27-84c8-b32c9fdfae4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Document is:\n",
      "[[0 0 0 1 1 0 0 1 0 1 0 1]\n",
      " [0 0 1 0 2 0 1 0 0 0 0 1]\n",
      " [1 1 0 1 1 1 0 1 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Encode the Document\n",
    "vector = vectorizer.transform(document)\n",
    "  \n",
    "# Summarizing the Encoded Texts\n",
    "print(\"Encoded Document is:\")\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b4e0a-4c35-4adb-a7c6-86e771b9b2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdbfb45-8303-4ed0-a9c8-11be705836cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        print(\"Articles:\",articles)\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e57a15-8fb6-4c9a-b953-09dbf3e9ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english' , ngram_range=(1,1),tokenizer=LemmaTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a1a23-0757-4782-90a3-21ccdb86af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(x_train)\n",
    "#vectorizer.get_feature_names_out()\n",
    "x_train_vectorized=vectorizer.transform(x_train)\n",
    "x_test_vectorized=vectorizer.transform(x_test)\n",
    "test_vectors = vectorizer.transform(test_data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540ef709-43aa-4938-ba03-14577d0b1a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4812e9f-640a-44be-83d2-aa5f14373720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a338b2bd-47f5-4394-a714-945ce2d3e51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
